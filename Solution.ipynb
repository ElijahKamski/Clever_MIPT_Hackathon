{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KOI4i3js55G"
      },
      "source": [
        "# MIPT forum in maths and AI. Hackathon. Clever classifying. Written by Yaroslav Khripkov. In \"collaboration\" with other members of BadLab Team "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEkLQEZAtLR-"
      },
      "source": [
        "Перед началом, хотелось бы сказать о том, что не вошло в этом решение, но что мы обдумывали и пытались реализовать. \n",
        "> ### 50 оттенков предобработки\n",
        "\n",
        "  Идеи были уже на этапе предобработки. Во-первых, использование готовых эмбеддингов, в частности были использованы компактные эмбеддинги navec. Помимо этого, данные были очищены от стоп-слов(что ухудшило качество классификации в данной задаче), очистка пунктуации, лемматизация слов. Последнее принесло небеольшой прирост качество, которым можно пожертвовать ради скорости работы и уменьшения вычислительной стоимости. После многих экспериментов мы решили, что в данной задаче знаки пунктуации, регистр символов и склонения несут большую смысловую нагрузку, но переписать свой \"пайплайн\" я не успевал, потому что исправлял модель в целом. \n",
        "  >### Война и  feature engineering\n",
        "\n",
        "  Как я уже говорил, мы проанализировали качество моделей после разных методов предобработки, что позволило оценить вклад подобных мелочей в общее качество. К сожалению, писать feature extrator'ы мы начали слишком поздно, хотя даже простой счётчик вопросительных знаков и анализ количества заглавных букв дали прирост в пару тысячных. Кто знает, что могло бы получиться в итоге?\n",
        "\n",
        "  >### Клуб борцов с дизбалансом классов\n",
        "\n",
        "то борьба с несбалансированной выборкой. В ходе неё мы(Я) решили, что классические алгоритмы ***oversampling*** хорошо подойдут для генерации вопросов от экспертов. Однако оверсэплинг над векторами предложений после токенизации только сбил нас с пути тем, что встроенные методы показывали отличное качество на отложенной, но в то же время, сгерерированной выборке. Признайтесь, вам бы тоже хотелось иметь ROC-AUC и F1-Score больше 0.97. Расслабившись на время, мы взялись за голову вечером, когда осознали свою ошибку. После этого мы думали, как расширить выборку, чтобы избавиться от дисбаланса классов. Здесь могла бы подойти ***генерация подобных предложений с помощью реккурентых нейросетей***, но на это не было ни ресурсов, ни времени. После этого, мы принялись искать готовые эбмеддинги для предложений, а не слов, но возникли некоторые трудности с их имплементацией, что отняло время и потребовало нового решения. Хоть как то себя показало ***усреднение эмбедингов всех слов в предложении, а потом оверсэмплинг***. Данная техника позволила простой нейросети без LSTM и подобного получить ROC-AUC ~ 0.66. \n",
        "  Готовые модели для определения автора текста показали себя примерно так же. Далее были эксперименты с архитектурой сети и тестирования алгоритмов машинного обучения других семейств. Так мы пришли к CatBoost, который смог нас удивить своим качеством классификации \"из коробки\"\n",
        "  >### Гарри Поттер и представление слов и предложений\n",
        "\n",
        "Я пытался выбрать нужные методы токенизации/векторизации предложений/слов. Из-за огромного множества подходов и готовых решений проблемно попробовать всё. Первой идеей было использование предобученных эмбеддингов ELMo и RuBERT от DeepPavlov.ai, но из-за конфликтов версий внутри фреймворка, пришлось от этого отказаться. Далее был выбран ранее используемый мной navec, который и оказался в финальной версии. Обучаемые эмбеддинги не стоили прироста в скорости так, как много теряли в качестве. К сожалению, не хватило времени попробовать fasttext в данной задаче, ведь было интересно посмотреть, как он здесь отработает\n",
        ">### Цветы для transfer learning\n",
        "\n",
        "Я уже был готов самовыписаться из программистов, когда час поиска в google и яндексе не дал результатов. Очень много материалов вели к вышеупомянутому DeepPavlov.ai и его RuBERT и ELMo, встриванию которого мешало малое количество примеров и постоянные проблемы с google colab, который так и норовил \"отвалиться\"\n",
        "\n",
        ">### Этюд в stacking'овых и enseble'вых тонах\n",
        "\n",
        "У нас было 2 дня хакатона, 75 пачек печенья, 5 банок энергетиков, полпачки сигарет..\n",
        "Естественно, большая часть времени ушла на очистку кода и его отладку. Некоторая - на research. Оставшегося категорически нехватало на отладку рабочей ансамблевой модели. Добавление всего лишь предсказания логистической регресии для предложения в выборку позволило увеличить метрику аж на одну десятую. Можно лишь представлять то, что бы выдавала модель, если бы к ней был добавлен еще и классификатор из KNearestNeighbours по эмбеддингам...\n",
        "\n",
        ">### Завершение\n",
        "\n",
        "Некоторые идеи были отвергнуты, многие остались нереализованными, а какие-то нашли своё место в нашем финальном решении. Возможно, я когда-нибудь вернусь к этому проекту, ведь проектов с NLP у меня было немного, а опыт нужен всегда. ***Было интересно работать над этой задачей, а еще интереснее, приятнее и полезнее Было бы по окончании форума и хакатона оказаться на стажировке)***\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgwzYL_54M6P"
      },
      "source": [
        "# Переходим от слов к делу. И к новым словам. Английским."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyW8YO4G5Esz"
      },
      "source": [
        "### Importing  and installing libraries. Unzip the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VallPyhEsa3R",
        "outputId": "9999a167-56f9-4190-ed4d-ed556472dc5c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import gensim\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install catboost\n",
        "import catboost\n",
        "from catboost import Pool, CatBoostClassifier\n",
        "from sklearn import model_selection\n",
        "!pip install natasha\n",
        "!pip install slovnet\n",
        "from string import punctuation\n",
        "from natasha import (\n",
        "    Segmenter,\n",
        "    MorphVocab,\n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    NewsSyntaxParser,\n",
        "    NewsNERTagger,\n",
        "    PER,\n",
        "    NamesExtractor,\n",
        "    Doc\n",
        ")\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import model_selection\n",
        "!unzip clever-mipt.zip\n",
        "\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: natasha in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: navec>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.10.0)\n",
            "Requirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: yargy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.15.0)\n",
            "Requirement already satisfied: slovnet>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: ipymarkup>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.0)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.19.5)\n",
            "Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.7/dist-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.3.0)\n",
            "Requirement already satisfied: slovnet in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: razdel in /usr/local/lib/python3.7/dist-packages (from slovnet) (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from slovnet) (1.19.5)\n",
            "Requirement already satisfied: navec in /usr/local/lib/python3.7/dist-packages (from slovnet) (0.10.0)\n",
            "Archive:  clever-mipt.zip\n",
            "replace Dockerfile? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JSvmEwB5WvY"
      },
      "source": [
        "Read the data from .csv ans selected neccesary features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IeqNO0A5Vsv"
      },
      "source": [
        "data=pd.read_csv('data.csv', sep=';', index_col=None)\n",
        "ans=pd.read_csv('train.csv', sep=';', index_col=None)\n",
        "data.drop('ID', axis=1)\n",
        "ans.drop('ID', axis=1)\n",
        "data['Question']=data['Question'].astype(str)\n",
        "data_train=data['Question'][:30000]\n",
        "data_test=data['Question'][30000:]\n",
        "\n",
        "noise = list(punctuation)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuh4RMP15ol7"
      },
      "source": [
        "Initialize some tools and create noise tokens list from punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsS9t1HjmgUE"
      },
      "source": [
        "noise = list(punctuation)\n",
        "segmenter = Segmenter()\n",
        "morph_vocab = MorphVocab()\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "syntax_parser = NewsSyntaxParser(emb)\n",
        "ner_tagger = NewsNERTagger(emb)\n",
        "names_extractor = NamesExtractor(morph_vocab)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIOiZZVt53pn"
      },
      "source": [
        "Take a look on our questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bitu09SDnw0K",
        "outputId": "8729a254-ba95-427c-bf93-a114ba8e208c"
      },
      "source": [
        "data_train"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Как зовут лодочника на реке Стикс в древнегреч...\n",
              "1                         Как в химии обозначается свинец?\n",
              "2        Какой химический элемент преобладает в составе...\n",
              "3        Кто из перечисленных был пажом во времена Екат...\n",
              "4                          Когда началась 2 мировая война?\n",
              "                               ...                        \n",
              "29995    Как называется игра, местом действия которой я...\n",
              "29996                 Как в опере называют ведущую певицу?\n",
              "29997                 На какой планете сутки длиннее года?\n",
              "29998    Сколько лет пролежал на печи известный богатыр...\n",
              "29999    В каком году основали Московский Государственн...\n",
              "Name: Question, Length: 30000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3IuuXGY58uV"
      },
      "source": [
        "I've already lemmatized the sentences for you not to waste time. Here we load cached data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "clxYk3qylzqx",
        "outputId": "338af6c8-f27a-4336-f7b3-09dd94ccf08e"
      },
      "source": [
        "#load file\n",
        "\n",
        "with open('train_lemmas.pkl', 'rb') as dummp:\n",
        "  x_train_lemma=pickle.load(dummp) \n",
        "'''\n",
        "x_train_lemma=[]\n",
        "for text in data_train:\n",
        "  doc=Doc(text)\n",
        "  doc.segment(segmenter)\n",
        "  doc.tag_morph(morph_tagger)\n",
        "  for token in doc.tokens:\n",
        "    token.lemmatize(morph_vocab)\n",
        "  lemmas=[_.lemma for _ in doc.tokens if _.text not in noise]\n",
        "  #print(lemmas)\n",
        "  x_train_lemma.append(lemmas)\n",
        "'''\n",
        "\n",
        "#load file\n",
        "\n",
        "with open('test_lemmas.pkl', 'rb') as dummp:\n",
        "  x_test_lemma=pickle.load(dummp) \n",
        "'''\n",
        "x_test_lemma=[]\n",
        "for text in data_test:\n",
        "  doc=Doc(text)\n",
        "  doc.segment(segmenter)\n",
        "  doc.tag_morph(morph_tagger)\n",
        "  for token in doc.tokens:\n",
        "    token.lemmatize(morph_vocab)\n",
        "  lemmas=[_.lemma for _ in doc.tokens if _.text not in noise]\n",
        "  #print(lemmas)\n",
        "  x_test_lemma.append(lemmas)\n",
        "'''"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nx_test_lemma=[]\\nfor text in data_test:\\n  doc=Doc(text)\\n  doc.segment(segmenter)\\n  doc.tag_morph(morph_tagger)\\n  for token in doc.tokens:\\n    token.lemmatize(morph_vocab)\\n  lemmas=[_.lemma for _ in doc.tokens if _.text not in noise]\\n  #print(lemmas)\\n  x_test_lemma.append(lemmas)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNWd3i_R6RX5"
      },
      "source": [
        "If you use another data you need to lemmatize it. You can do it using the code above. To save lemmas use the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "35Hdq0EYk-ma",
        "outputId": "e39cce14-1707-4366-de80-013b8440244f"
      },
      "source": [
        "'''with open('train_lemmas.pkl', 'wb') as lemms:\n",
        "  pickle.dump(x_train_lemma, lemms)\n",
        "with open('test_lemmas.pkl', 'wb') as lemms:\n",
        "  pickle.dump(x_test_lemma, lemms)'''"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"with open('train_lemmas.pkl', 'wb') as lemms:\\n  pickle.dump(x_train_lemma, lemms)\\nwith open('test_lemmas.pkl', 'wb') as lemms:\\n  pickle.dump(x_test_lemma, lemms)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04QwV8tp6gyu"
      },
      "source": [
        "List of lemmas back to string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP_VnmH7oHO9"
      },
      "source": [
        "xtk=np.array([' '.join(i) for i in x_train_lemma])\n",
        "xttk=np.array([' '.join(i) for i in x_test_lemma])\n",
        "x_test=xttk"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1_zt6cf6nIH"
      },
      "source": [
        "Ok. Everybody is doing it. No comments. Ok. Splitting the data for calculating metrics on unviewed samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c77DQ9IxuocQ"
      },
      "source": [
        "x_train,x_val,y_train,y_val=model_selection.train_test_split(xtk, ans.Answer,test_size=0.2)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh_DuywC63a-"
      },
      "source": [
        "Transform arrays to pandas DataFrame as it requires CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKArImpTu_Z4"
      },
      "source": [
        "train_d=pd.DataFrame(x_train, columns=['Question'])\n",
        "val_d=pd.DataFrame(x_val, columns=['Question'])\n",
        "test_d=pd.DataFrame(x_test, columns=['Question'])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMCCNOmR6_jY"
      },
      "source": [
        "Defining a function to build and train our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaFlbf3ItKHu"
      },
      "source": [
        "def fit_catboost_on_Clever(X_train, X_test, y_train, y_test, catboost_params={}, verbose=100):\n",
        "    learn_pool = Pool(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        text_features=['Question'],\n",
        "        feature_names=list(X_train.columns),\n",
        "    )\n",
        "    test_pool = Pool(\n",
        "        X_test,\n",
        "        y_test,\n",
        "        text_features=['Question'],\n",
        "        feature_names=list(X_train.columns)\n",
        "    )\n",
        "\n",
        "    catboost_default_params = {\n",
        "        'iterations': 500,\n",
        "        'learning_rate': 0.1,\n",
        "        'eval_metric': 'AUC',\n",
        "        'task_type':'GPU'\n",
        "    }\n",
        "\n",
        "    catboost_default_params.update(catboost_params)\n",
        "\n",
        "    model = CatBoostClassifier(**catboost_default_params)\n",
        "    model.fit(learn_pool, eval_set=test_pool, verbose=verbose)\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5DLww6L7Gvl"
      },
      "source": [
        "Loading the pretrained model not to waste time on fitting it again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjSep5C6r3jp",
        "outputId": "60efaf91-0f97-4fd7-afc0-a037b275e812"
      },
      "source": [
        "model=catboost.CatBoostClassifier()\n",
        "model.load_model(fname='CatBoost_Clever_by_ElijahKamski')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fb782adfa50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81LdHaJs7Qsp"
      },
      "source": [
        "If you need to refit it just uncomment the string below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skZxq8tvwdqG"
      },
      "source": [
        "#model=fit_catboost_on_Clever(train_d,val_d, y_train,y_val)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d3S8ZMK7XIk"
      },
      "source": [
        "Calculating our predictions and saving it to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2jfkU9hrNah"
      },
      "source": [
        "pd.DataFrame(model.predict_proba(test_d)[:,1], index=list(range(30001, 30000+test_d.shape[0]+1))).to_csv('answer_cat.csv', header=None)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zw8pBEj7cvw"
      },
      "source": [
        "If you for any reason need to save model again you know what to do"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB4WPQtrzxHH"
      },
      "source": [
        "#model.save_model('CatBoost_Clever_by_ElijahKamski')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI5A0Klx7ki1"
      },
      "source": [
        "Thank you for interesting in my projects. And special thanks to the MIPT for this forum. I hope some time I would learn here and work maybe in Mail.Ru Group. Who knows what is going to happen?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz7qVwSP7_rG"
      },
      "source": [
        ""
      ],
      "execution_count": 67,
      "outputs": []
    }
  ]
}
